{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Urlk69qAp8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "#If you enable GPU here, device will be cuda, otherwise it will be cpu\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJnRv2s4HwMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#DOWNLOADING DATA SET\n",
        "\n",
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '1ORrHW9moXLcWwg8WY9o-Ulq8X9BAiD1P'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train.pkl')  \n",
        "\n",
        "id = '1eb4gtE8XlN3TcZqzwS18Ik-H7MFAeW4z'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('label.pkl')  \n",
        "\n",
        "import pickle\n",
        "input_embeddings = pickle.load(open(\"train.pkl\",\"rb\"))\n",
        "label = pickle.load(open(\"label.pkl\",\"rb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FVk0oaBH1Ba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SPLIT THE DATASET\n",
        "\n",
        "# Split into training and testing dataset using scikit-learn\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_embeddings, test_embeddings, train_label, test_label = train_test_split(input_embeddings,label,test_size = 0.2, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zk-ohzCH6Fr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GENERATE BATCH\n",
        "\n",
        "def generate_batch(input_embeddings, label, batch_size):\n",
        "    idx = np.random.randint(input_embeddings.shape[0], size=batch_size)\n",
        "    return input_embeddings[idx,:,:],label[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwqt7CBsH8jS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MODEL\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.lstm = nn.LSTM(n_input, n_hidden, batch_first =True)\n",
        "        self.linear = nn.Linear(n_hidden, n_class)\n",
        "\n",
        "    def forward(self, x):        \n",
        "        \n",
        "        #forward propogation\n",
        "\n",
        "        # lstm layer\n",
        "        x,_ = self.lstm(x)\n",
        "        # linear layer\n",
        "        x = self.linear(x[:,-1,:])\n",
        "        # softmax layer\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "              \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zWji82-IDJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "\n",
        "# Please assign values to these variables by using other variables (instead of hard code)\n",
        "seq_length = len(train_embeddings[0])\n",
        "n_input = len(train_embeddings[0][0])\n",
        "n_class = len(list(set(train_label)))\n",
        "\n",
        "#Please decide the hyperparameters here by yourself\n",
        "n_hidden = 128\n",
        "batch_size = 128\n",
        "total_epoch = 1000\n",
        "learning_rate = 0.01\n",
        "shown_interval = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw28VVmUIFOX",
        "colab_type": "code",
        "outputId": "eeb14d68-f64f-4556-ba4c-767fda260fb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "net = Net().to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# optimizer to provide higher F1\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(total_epoch):\n",
        "\n",
        "    input_batch, target_batch = generate_batch(train_embeddings,train_label, batch_size)\n",
        "    input_batch_torch = torch.from_numpy(input_batch).float().to(device)\n",
        "    target_batch_torch = torch.from_numpy(target_batch).view(-1).to(device)\n",
        "\n",
        "    net.train()\n",
        "    outputs = net(input_batch_torch) \n",
        "    loss = criterion(outputs, target_batch_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if epoch % shown_interval == shown_interval-1:\n",
        "        net.eval()\n",
        "        outputs = net(input_batch_torch) \n",
        "        train_loss = criterion(outputs, target_batch_torch)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        train_acc= accuracy_score(predicted.cpu().numpy(),target_batch_torch.cpu().numpy())\n",
        "\n",
        "        print('Epoch: %d, train loss: %.5f, train_acc: %.4f'%(epoch + 1, train_loss.item(), train_acc))\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "## Prediction\n",
        "net.eval()\n",
        "outputs = net(torch.from_numpy(test_embeddings).float().to(device)) \n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_label, predicted.cpu().numpy(),digits=4))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100, train loss: 1.42527, train_acc: 0.3281\n",
            "Epoch: 200, train loss: 1.29339, train_acc: 0.3516\n",
            "Epoch: 300, train loss: 1.01881, train_acc: 0.5312\n",
            "Epoch: 400, train loss: 0.91895, train_acc: 0.5234\n",
            "Epoch: 500, train loss: 1.12914, train_acc: 0.4219\n",
            "Epoch: 600, train loss: 0.35257, train_acc: 0.7734\n",
            "Epoch: 700, train loss: 0.23266, train_acc: 0.8125\n",
            "Epoch: 800, train loss: 0.30713, train_acc: 0.8281\n",
            "Epoch: 900, train loss: 0.27370, train_acc: 0.8594\n",
            "Epoch: 1000, train loss: 0.11848, train_acc: 0.9609\n",
            "Finished Training\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6147    0.7204    0.6634        93\n",
            "           1     0.9500    0.9344    0.9421       122\n",
            "           2     0.8947    0.9358    0.9148       109\n",
            "           3     0.7339    0.6250    0.6751       128\n",
            "\n",
            "    accuracy                         0.8031       452\n",
            "   macro avg     0.7983    0.8039    0.7989       452\n",
            "weighted avg     0.8065    0.8031    0.8026       452\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}