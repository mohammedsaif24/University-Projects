{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MOHA6885_COMP5046_Ass1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGHoy6KpQDfZ",
        "colab_type": "text"
      },
      "source": [
        "# COMP5046 Assignment 1\n",
        "*Make sure you change the file name with your unikey.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbW6bynfcjbc",
        "colab_type": "code",
        "outputId": "ea7706d4-298f-4262-bc83-967f7d79a14f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTf21j_oQIiD",
        "colab_type": "text"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the user, please mention here.* \n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXbQohXLKSgO",
        "colab_type": "text"
      },
      "source": [
        "***Visualising the comparison of different results is a good way to justify your decision.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34DVNKgqQY21",
        "colab_type": "text"
      },
      "source": [
        "# 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cWUxAQrGlq6",
        "colab_type": "text"
      },
      "source": [
        "## 1.1. Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7C4snIcNl22",
        "colab_type": "code",
        "outputId": "a0629caf-537d-4f60-a917-98e5ab3b3895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '1vF3FqgBC1Y-RPefeVmY8zetdZG1jmHzT'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('imdb_train.csv')\n",
        "\n",
        "id = '1XhaV8YMuQeSwozQww8PeyiWMJfia13G6'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('imdb_test.csv')\n",
        "\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"imdb_train.csv\")\n",
        "df_test = pd.read_csv(\"imdb_test.csv\")\n",
        "\n",
        "reviews_train = df_train['review'].tolist()\n",
        "sentiments_train = df_train['sentiment'].tolist()\n",
        "reviews_test = df_test['review'].tolist()\n",
        "sentiments_test = df_test['sentiment'].tolist()\n",
        "\n",
        "print(\"Training set number:\",len(reviews_train))\n",
        "print(\"Testing set number:\",len(reviews_test))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set number: 25000\n",
            "Testing set number: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9gBSgBCQh24",
        "colab_type": "text"
      },
      "source": [
        "## 1.2. Preprocess data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RdKI8E2KRwe",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe which data preprocessing techniques were conducted with justification of your decision. *"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emyl1lWxGr12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code\n",
        "import pprint as pp\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#CSV file has 25000 reviews. But these reviews have < br/> tags, which are removed using regex expressions\n",
        "\n",
        "def remove_HTML_tags(x):\n",
        "    x = re.sub(r'\\<br \\/\\>',' ',x)   #removes <br \\> tags\n",
        "    removeSlash = re.compile(r\"[\\\\\\']\")\n",
        "    #replacement = re.compile(r\"\\'\")\n",
        "    #x = re.sub(r\"[^a-z0-9]+\", \" \", x.lower()) \n",
        "    #x = re.sub(removeSlash,'^',x) \n",
        "    return x\n",
        "\n",
        "\n",
        "reviews_train_cleaned = []\n",
        "\n",
        "for item in range(0, len(reviews_train)):\n",
        "  reviews_train_cleaned.append(remove_HTML_tags(reviews_train[item]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIu_lkJwQ55g",
        "colab_type": "text"
      },
      "source": [
        "# 2 - Model Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daDvAftceIvr",
        "colab_type": "text"
      },
      "source": [
        "## 2.1. Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbzm-NWBTmM-",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe which model was implemented (i.e. Word2Vec with CBOW, FastText with SkipGram, etc.) with justification of your decision *"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cM4rlYkHefJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code\n",
        "\n",
        "# We will be implementing Word2Vec with skipgrams\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXgFpxIgl-_G",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.1. Data Preprocessing for Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJrVHGYSmYMg",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe which preprocessing techniques were used with justification of your decision.*\n",
        "\n",
        "**Important**: If you are going to use the code from lab3 word2vec preprocessing. Please note that `word_list = list(set(word_list)) ` has randomness. So to make sure the word_list is the same every time you run it, you can put `word_list.sort()` after that line of code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P7XjliBzekx2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a0afea04-50eb-497c-9c15-27336561fb5d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import pprint\n",
        "import re\n",
        "from lxml import etree\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "tknzr = TweetTokenizer()\n",
        "\n",
        "#removal of all punctuations - .,?!_-\n",
        "def remove_punctuation_re(x):\n",
        "    #x = re.sub(r'[^\\w\\s]','',x)\n",
        "    x = re.sub(r'[^\\w\\s]',' ',x)    #replacing with space, maybe it will help?\n",
        "    return x\n",
        "\n",
        "def remove_underscores_re(x):\n",
        "    x = re.sub(r'_',' ',x)    #replacing with space, maybe it will help?\n",
        "    return x\n",
        "\n",
        "def remove_numbers_re(x):\n",
        "  x = re.sub(r'[0-9]+',' ',x)    #replacing with space, maybe it will help?\n",
        "  return x\n",
        "\n",
        "\n",
        "reviews_train_Without_Punctuations = []\n",
        "\n",
        "# Removing all punctuations\n",
        "for item in range(0, len(reviews_train_cleaned)):\n",
        "  reviews_train_Without_Punctuations.append(remove_punctuation_re(reviews_train_cleaned[item]))\n",
        "\n",
        "reviews_train_Without_Underscore = []\n",
        "\n",
        "#Removing underscore\n",
        "for item in range(0, len(reviews_train_Without_Punctuations)):\n",
        "  reviews_train_Without_Underscore.append(remove_underscores_re(reviews_train_Without_Punctuations[item]))\n",
        "\n",
        "reviews_train_Without_Numbers = []\n",
        "#Remove numbers\n",
        "for item in range(0, len(reviews_train_Without_Underscore)):\n",
        "  reviews_train_Without_Numbers.append(remove_numbers_re(reviews_train_Without_Underscore[item]))\n",
        "\n",
        "\n",
        "# Tokenising the sentence to process it by using NLTK library\n",
        "sent_text_NLTK =[]\n",
        "for i in range (0, len(reviews_train_Without_Numbers)):\n",
        "  sent_text_NLTK.append(sent_tokenize(reviews_train_Without_Numbers[i]))\n",
        "\n",
        "#pp.pprint(sent_text_NLTK[0])\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNfdnchy1cAJ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3pJnbaiwbhG",
        "colab_type": "code",
        "outputId": "a7cc6f16-87e5-4e01-8d85-3ff8782f8a58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords as sw\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "normalized_text = []\n",
        "\n",
        "#tokenizing the sentences\n",
        "for reviews in sent_text_NLTK:\n",
        "  for sent in reviews:\n",
        "    #tokens = re.sub(r\"[^a-z0-9]+\", \" \", sent.lower())\n",
        "    tokens = word_tokenize(sent.lower()) #converting all words to lower case \n",
        "    #for token in tokens:\n",
        "    normalized_text.append(tokens)\n",
        "\n",
        "text_train_ns=[]\n",
        "stop_words = sw.words()\n",
        "for tokens in normalized_text:\n",
        "    filtered_sentence = [w for w in tokens if not w in stop_words]\n",
        "    text_train_ns.append(filtered_sentence)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICh9T2QgtqrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newlist = []\n",
        "list_unique_words = []\n",
        "#print(text_train_ns[0])\n",
        "\n",
        "\n",
        "def remove_accentedCharacters_re(x):\n",
        "  x = re.sub(r'[^a-z]','',x)    #replacing with space, maybe it will help?\n",
        "  return x\n",
        "\n",
        "\n",
        "#Flatening the List of list to a single list - A single list of all words\n",
        "for sentences in text_train_ns:\n",
        "  for words in sentences:\n",
        "    words = words.lower()\n",
        "    newlist.append(remove_accentedCharacters_re(words))    # remove accented chars\n",
        "\n",
        "\n",
        "#Assigning the unaltered list\n",
        "word_sequence = newlist\n",
        "\n",
        "#Removal of duplicates\n",
        "set_Unique_Words = set (newlist)\n",
        "\n",
        "#Converting the set back to a list\n",
        "for items in set_Unique_Words:\n",
        "  list_unique_words.append(items)\n",
        "\n",
        "list_unique_words.sort()\n",
        "\n",
        "#Assigning the unique word list\n",
        "word_list = list_unique_words\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0ws0QYboVH_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make dictionary so that we can reference each index of unique word\n",
        "word_dict = {w: i for i, w in enumerate(word_list)}\n",
        "\n",
        "# Making window size 1 skip-gram\n",
        "# i.e.) he likes cat\n",
        "#   -> (he, [likes]), (likes,[he, cat]), (cat,[likes])\n",
        "#   -> (he, likes), (likes, he), (likes, cat), (cat, likes)\n",
        "skip_grams = []\n",
        "\n",
        "\n",
        "# Word_Sequence is the unaltered list of words/ tokens from the corpus\n",
        "for i in range(1, len(word_sequence) - 1):\n",
        "    # (context, target) : ([target index - 1, target index + 1], target)\n",
        "    target = word_dict[word_sequence[i]]\n",
        "    context = [word_dict[word_sequence[i - 1]], word_dict[word_sequence[i + 1]]]\n",
        "\n",
        "    # skipgrams - (target, context[0]), (target, context[1])..\n",
        "    for w in context:\n",
        "        skip_grams.append([target, w])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcgJ-IQ5o84k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "voc_size = len(word_list)\n",
        "\n",
        "# prepare random batch from skip-gram - we do not have enought data so we randomly select data\n",
        "def prepare_batch(data, size):\n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_index = np.random.choice(range(len(data)), size, replace=False)\n",
        "\n",
        "    for i in random_index:\n",
        "        input_temp = [0]*voc_size\n",
        "        input_temp[data[i][0]] = 1\n",
        "        random_inputs.append(input_temp)  # target\n",
        "        random_labels.append(data[i][1])  # context word\n",
        "\n",
        "    return np.array(random_inputs), np.array(random_labels)\n",
        "\n",
        "\n",
        "learning_rate = 0.1\n",
        "batch_size = 800\n",
        "embedding_size = 51   #max length of characters\n",
        "no_of_epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhAgWf_AmbZ8",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.2. Build Word Embeddings Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ8rU7JbiBVS",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVPuwWgvNjOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwzKFRTGDWE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "class SkipGram(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SkipGram, self).__init__()\n",
        "        #You need to use \"bias=False\" when you define Linear functions\n",
        "        #***************put your code here***************\n",
        "        self.linear1 = nn.Linear(voc_size, embedding_size, bias=False)\n",
        "        self.linear2 = nn.Linear(embedding_size, voc_size, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden = self.linear1(x)\n",
        "        out = self.linear2(hidden)\n",
        "        return out\n",
        "\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNys5HOdISK-",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.3. Train Word Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae8i7Z2kIef-",
        "colab_type": "code",
        "outputId": "fca98047-15b7-4406-c99d-3b0f6266a0ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# Please comment your code\n",
        "skip_gram_model = SkipGram()\n",
        "criterion = nn.CrossEntropyLoss() #please note we are using \"CrossEntropyLoss\" here\n",
        "optimiser = optim.SGD(skip_gram_model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "\n",
        "#outputs = torch.from_numpy(outputs)\n",
        "for epoch in range(100):\n",
        "\n",
        "    inputs,labels = prepare_batch(skip_grams, batch_size)\n",
        "    inputs_torch = torch.from_numpy(inputs).float()  #feeding one hot encodings of context word\n",
        "    labels_torch = torch.from_numpy(labels)          #feeding label of target word\n",
        "\n",
        "    #***************put your code here***************\n",
        "    # 1. zero grad\n",
        "    # 2. forword propagation\n",
        "    # 3. calculate loss\n",
        "    # 4. back propagation\n",
        "\n",
        "    skip_gram_model.train()\n",
        "    # zero the parameter gradients\n",
        "    optimiser.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    \n",
        "    output_label = skip_gram_model(inputs_torch)\n",
        "    loss = criterion(output_label, labels_torch) # We don't need to calcualte logsoftmax here\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "\n",
        "\n",
        "    if epoch % 10 == 0: \n",
        "      print('Epoch: %d, loss: %.4f' %(epoch + 1, loss))\n",
        "\n",
        "\n",
        "#get the weight from a Model Linear layer\n",
        "weight = skip_gram_model.linear2.weight\n",
        "trained_embeddings = weight.detach().T.numpy()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, loss: 10.1845\n",
            "Epoch: 11, loss: 10.1845\n",
            "Epoch: 21, loss: 10.1846\n",
            "Epoch: 31, loss: 10.1845\n",
            "Epoch: 41, loss: 10.1845\n",
            "Epoch: 51, loss: 10.1846\n",
            "Epoch: 61, loss: 10.1844\n",
            "Epoch: 71, loss: 10.1845\n",
            "Epoch: 81, loss: 10.1844\n",
            "Epoch: 91, loss: 10.1845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMCv3YI1IfUo",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.4. Save Word Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OwicNPkIqd1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "6b43e7c8-7816-488d-f77b-42ad51434772"
      },
      "source": [
        "# Please comment your code\n",
        "torch.save(skip_gram_model, 'word_embedding_model.pt')\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b8c42983110f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip_gram_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'word_embedding_model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'skip_gram_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn16xrDrIs8B",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.5. Load Word Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IebpYFsIvgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# File is saved with sharing mode on, kindly run this cell to download onto your drive\n",
        "# Run the model class first for this to work \n",
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "id = '1-05c9pMCI-F3EJ9G7hnw7Y1ibB75rVoK'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('word_embedding_model.pt')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOqayptklXXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saved_skip_gram_model = torch.load('word_embedding_model.pt')\n",
        "saved_skip_gram_model.eval()\n",
        "skipgram_weight = saved_skip_gram_model.linear2.weight\n",
        "trained_embeddings_skipgram = skipgram_weight.detach().T.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T0ap96aeGlIk"
      },
      "source": [
        "## 2.2. Character Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d16v3oKaGlI0"
      },
      "source": [
        "### 2.2.1. Data Preprocessing for Character Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AKbLnN-3GlI1"
      },
      "source": [
        "*You are required to describe which preprocessing techniques were used with justification of your decision.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i2CUCL1cGlI2",
        "colab": {}
      },
      "source": [
        "# Please comment your code\n",
        "import numpy as np\n",
        "import pprint as pp\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# newlist has tokenized words from training data including duplicates (Corpus)\n",
        "# list_unique_words has tokenized unique words in a list\n",
        "\n",
        "\n",
        "\n",
        "#--------------------------------\n",
        "\n",
        "#Assume that we have the following character instances\n",
        "char_arr = ['a', 'b', 'c', 'd', 'e', 'f', 'g',\n",
        "            'h', 'i', 'j', 'k', 'l', 'm', 'n',\n",
        "\n",
        "            'o', 'p', 'q', 'r', 's', 't', 'u',\n",
        "            'v', 'w', 'x', 'y', 'z', '0']\n",
        "\n",
        "# one-hot encoding and decoding \n",
        "# {'a': 0, 'b': 1, 'c': 2, ..., 'j': 9, 'k', 10, ...}\n",
        "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
        "dic_len = len(num_dic)\n",
        "\n",
        "\n",
        "len_list = [len(s) for s in list_unique_words]\n",
        "seq_length = max(len_list)\n",
        "\n",
        "#Padding the words to make all words of the same size\n",
        "def add_padding(corpus, seq_length):\n",
        "    output = []\n",
        "    for sentence in corpus:\n",
        "        if len(sentence)>seq_length:\n",
        "            output.append(sentence[:seq_length])\n",
        "        else:\n",
        "            for j in range(seq_length-len(sentence)):\n",
        "                #sentence.append(\"<PAD>\")\n",
        "                sentence = sentence+\"0\"\n",
        "            output.append(sentence)\n",
        "    return output\n",
        "\n",
        "#Padding the words to make all words of the same size\n",
        "text_train_pad = add_padding(list_unique_words,seq_length )\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnzczhyNwZqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a list words for sequence data (input and output)\n",
        "seq_data = text_train_pad\n",
        "\n",
        "# Make a batch to have sequence data for input and ouput\n",
        "def make_batch(seq_data):\n",
        "    input_list = []\n",
        "    input_batch = np.array(input_list)\n",
        "\n",
        "    target_batch = []\n",
        "    \n",
        "    for seq in seq_data:\n",
        "        # input data is:\n",
        "        #     wor           woo        dee       div\n",
        "        # [22, 14, 17] [22, 14, 14] [3, 4, 4] [3, 8, 21] ...\n",
        "        \n",
        "        input_data = [num_dic[n] for n in seq]\n",
        "\n",
        "        \n",
        "        # convert input to one-hot encoding.\n",
        "        # if input is [3, 4, 4]:\n",
        "        # [[ 0,  0,  0,  1,  0,  0,  0, ... 0]\n",
        "        #  [ 0,  0,  0,  0,  1,  0,  0, ... 0]\n",
        "        #  [ 0,  0,  0,  0,  1,  0,  0, ... 0]]\n",
        "        #input_batch.append(np.eye(dic_len)[input_data])\n",
        "        input_batch = np.eye(dic_len)[input_data]\n",
        "\n",
        "        target_batch.append(input_batch)\n",
        "        #target_batch.append([target])\n",
        "\n",
        "    return target_batch\n",
        "\n",
        "input_batch2 = np.array(make_batch(seq_data))\n",
        "\n",
        "target_batch2 = trained_embeddings_skipgram\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zgiOPcsTGlI6"
      },
      "source": [
        "### 2.2.2. Build Character Embeddings Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4NtqFFcjGlI7"
      },
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jj3YZ3PWGlI8",
        "colab": {}
      },
      "source": [
        "### Setting hyperparameters\n",
        "\n",
        "learning_rate = 0.1\n",
        "n_hidden = 30\n",
        "total_epoch = 50\n",
        "\n",
        "# Number of sequences for RNN\n",
        "n_step = 3\n",
        "\n",
        "# number of inputs (dimension of input vector) = 27\n",
        "n_input = dic_len\n",
        "# number of classes = 27\n",
        "\n",
        "#n_class = dic_len\n",
        "#n_class is the size of the word embedding\n",
        "n_class = 51\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # LSTM layer, the batch_first is False by default, which means the input and output tensors are provided as (seq_len, batch_size, feature) \n",
        "        # We need to set it to True because we are using input of shape (batch_size, seq_len, feature)  \n",
        "        # Apply dropout to prevent overfitting, you can try to change the dropout rate. Note that this dropout is applied on outputs of each LSTM layer except the last layer\n",
        "        self.lstm = nn.LSTM(n_input, n_hidden, num_layers=2, batch_first =True, dropout=0.2)\n",
        "        # Linear layer for output\n",
        "        self.linear = nn.Linear(n_hidden,n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # There are two outputs from nn.LSTM:\n",
        "        # 1. tensor of shape (batch_size, seq_len, hidden_size) containing the output features from the last layer of the LSTM for each time step t\n",
        "        # 2. the tuple containing the hidden state and cell state.  \n",
        "        # Here we only care about the first output. Details for the two outputs can be found in PyTorch documentation for nn.LSTM: https://pytorch.org/docs/stable/nn.html#lstm\n",
        "        x,_ = self.lstm(x)\n",
        "        # Here we extract only the last hidden state from the LSTM output features\n",
        "        # The last hidden carries the information about what the LSTM cell has seen over the time. \n",
        "        # Thus the prediction based on the last hidden state not only considers the data at the current time step, instead, it considers historical data.\n",
        "        x = self.linear(x[:,-1,:])\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "46W0zFfWGlI_"
      },
      "source": [
        "### 2.1.4. Train Character Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UWQn-VyNGlJA",
        "colab": {}
      },
      "source": [
        "# Please comment your code\n",
        "import torch\n",
        "#You can enable GPU here (cuda); or just CPU\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to GPU\n",
        "#net = Net().to(device)\n",
        "net = Net()\n",
        "\n",
        "# Loss function and optimizer\n",
        "#criterion = nn.NLLLoss()\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "# Preparing input\n",
        "#input_batch = make_batch(seq_data)\n",
        "#target_batch = trained_embeddings_skipgram\n",
        "\n",
        "#test input\n",
        "input_batch = make_batch(seq_data)\n",
        "target_batch = trained_embeddings_skipgram\n",
        "\n",
        "\n",
        "\n",
        "# Convert input into tensors and move them to GPU by uting tensor.to(device)\n",
        "#input_batch_torch = torch.from_numpy(np.array(input_batch)).float().to(device)\n",
        "#target_batch_torch = torch.from_numpy(np.array(target_batch)).view(-1).to(device)\n",
        "\n",
        "input_batch_torch = torch.from_numpy(np.array(input_batch)).float()\n",
        "target_batch_torch = torch.from_numpy(np.array(target_batch.T))\n",
        "\n",
        "\n",
        "for epoch in range(total_epoch):  \n",
        "    \n",
        "    # Set the flag to training\n",
        "    net.train()\n",
        "    \n",
        "    # forward + backward + optimize\n",
        "    outputs = net(input_batch_torch) \n",
        "    loss = criterion(outputs, target_batch_torch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Set the flag to evaluation, which will 'turn off' the dropout\n",
        "    net.eval()\n",
        "    outputs = net(input_batch_torch) \n",
        "    \n",
        "    # Evaluation loss and accuracy calculation\n",
        "    loss = criterion(outputs, target_batch_torch)\n",
        "    #_, predicted = torch.max(outputs, 1)\n",
        "    #acc= accuracy_score(predicted.cpu().numpy(),target_batch_torch.cpu().numpy())\n",
        "\n",
        "    print('Epoch: %d, loss: %.5f' %(epoch + 1, loss.item()))\n",
        "\n",
        "print('Finished Training')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEcoiJ5BFCoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "e6de7dae-fde5-4bda-d53f-90af1b7e9d3c"
      },
      "source": [
        "net.eval()\n",
        "hidden_state = net(input_batch_torch)\n",
        "print(n_hidden)\n",
        "print(len(seq_data)) \n",
        "print(hidden_state.size())\n",
        "print(hidden_state.data)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "72732\n",
            "torch.Size([72732, 51])\n",
            "tensor([[-3.9320, -3.9322, -3.9521,  ..., -3.9422, -3.9473, -3.9254],\n",
            "        [-3.9336, -3.9319, -3.9540,  ..., -3.9421, -3.9472, -3.9271],\n",
            "        [-3.9332, -3.9319, -3.9536,  ..., -3.9420, -3.9473, -3.9268],\n",
            "        ...,\n",
            "        [-3.9323, -3.9320, -3.9529,  ..., -3.9418, -3.9476, -3.9266],\n",
            "        [-3.9272, -3.9330, -3.9466,  ..., -3.9423, -3.9478, -3.9209],\n",
            "        [-3.9392, -3.9316, -3.9584,  ..., -3.9434, -3.9457, -3.9303]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R5Bym9bBGlJE"
      },
      "source": [
        "### 2.1.5. Save Character Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ggTsYIm7GlJF",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JwOI-wIKGlJI"
      },
      "source": [
        "### 2.1.6. Load Character Embeddings Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-jyj-lOHWWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlCeWT8eeLnd",
        "colab_type": "text"
      },
      "source": [
        "## 2.3. Sequence model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwA-NN3EJ4Ig",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.1. Apply/Import Word Embedding and Character Embedding Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAMJrxx-iOVn",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7PKX1gIePA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpYCL17JKZxl",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.2. Build Sequence Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R204UIyDKhZ4",
        "colab_type": "text"
      },
      "source": [
        "*You are required to describe how hyperparameters were decided with justification of your decision.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13eCtR_SLUG6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BaOiaGRLW7R",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.3. Train Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVQnUSX1LZ6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2feNpG-LZx2",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.4. Save Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sflUAgV4L1o8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zFo6YppL6w3",
        "colab_type": "text"
      },
      "source": [
        "### 2.3.5. Load Sequence Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtNxLzDGMCan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4mpRpocePLN",
        "colab_type": "text"
      },
      "source": [
        "# 3 - Evaluation\n",
        "\n",
        "(*Please show your empirical evidence*)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEW1zMgVMREr",
        "colab_type": "text"
      },
      "source": [
        "## 3.1. Performance Evaluation\n",
        "\n",
        "\n",
        "You are required to provide the table with precision, recall, f1 of test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPHCb-bneTI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P28Z1k36MZuo",
        "colab_type": "text"
      },
      "source": [
        "## 3.2. Hyperparameter Testing\n",
        "*You are required to draw a graph(y-axis: f1, x-axis: epoch) for test set and explain the optimal number of epochs based on the learning rate you have already chosen.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTLyQEeZMZ2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Please comment your code"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfv8rWTKPzeb",
        "colab_type": "text"
      },
      "source": [
        "## Object Oriented Programming codes here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS23AjBRSZaX",
        "colab_type": "text"
      },
      "source": [
        "*You can use multiple code snippets. Just add more if needed* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1hVmx4E52dXS",
        "colab": {}
      },
      "source": [
        "# If you used OOP style, use this section"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}