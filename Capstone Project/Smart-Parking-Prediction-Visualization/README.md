# 21-S1-Smart-Parking-Prediction-Visualization
2021-S1-CS25 Smart Parking Prediction and Visualization in Melbourne City 


**Description**: Often times, people find it hard to find empty parking spots in busy areas and spend a long time circling the area leading to higher congestion levels. Higher congestion levels usually lead to higher waiting times for other drivers which only adds to their frustration. Individuals stuck in traffic often report lower satisfaction levels which then has implications on their happiness levels. Lastly, lower happiness levels of residents affect the livability ratings of a city. This project aims to ease these pain points by developing a smart parking application that can visualise and predict parking availabilities in Melbourne Central Business District Area. This repository contains the code for a web application that visualises and predicts parking availabilties in Melbourne City.

**Dataset**: This dataset is available on Socrata's website https://dev.socrata.com/foundry/data.melbourne.vic.gov.au/vh2v-4nfs and it's information is available on Melbourne City Council website https://data.melbourne.vic.gov.au/Transport/On-street-Parking-Bays/crvt-b4kt.
There are 2 types of datasets available on their website- Historical and Real time. Historical datasets are available for complete years until 2019 and between the months of Jan and March of 2020. Real time data is accessible through an API end point available on their website and is updated every 2 mins. 

**Model**: Multiple models were built and tested on this dataset and the model with the highest accuracy was used in the application. The best model uses Random Forest algorithm and is extracted inside the application from a saved state file. The model is stored at https://drive.google.com/file/d/1tfQTM5W5XPUJIkXUyU3K9sbiFRvIaKzQ/view?usp=sharing. It should be placed inside ml_models folder.

**User Accounts**: The application requires the client secrets file of the account that is associated with Google Drive. This file was generated by enabling drive API access inside Google Cloud Console. The application also requires the developer to create an account with MapboxGL in order to generate a token that can be used by the application to access the libraries.

**Deployment**: This project has multiple code files that work together to function as a web application. The otherFiles folder contains static datasets that the application needs for it's function - Bay restriction information and Bay location coordinates. The templates folder contains the user interface (UI) templates which use HTML, CSS and Javascript code. The root folder contains a few Python files. The main files that are needed for this application to function are main.py and custom_modules.py. Whichever environment this code is deployed on, the directory structure should be maintained the way it is in the repo as the paths inside the application are relative to it. The requirements.txt file contains the names and versions of all Python packages required by the application.

This repo also contains the code to automate the downloading and storage of real time data on Google Drive in realTimeDataStorageScript.py. This script needs to be deployed on a system which is available 24x7 and has access to the internet. This can be done on any remote server/virtual instance. This script needs Google Drive access permissions and these permissions can be granted to it by storing client_secrets.json and creds.json files in it's path. These files can be generated by running the authenticationTokenGnerator.py file with settings.yaml in it's directory. The setting.yaml file needs the client id and client secrets field and this can be obtained from this website- https://console.cloud.google.com/. These steps are required because of Google Cloud security reasons. 

The steps to deploy this application are as follows:
1) Schedule real time data storage Python script
2) Install Python packages from requirements.txt
3) Store the files according to the directory structure of this application. Download the ml model from drive path above inside ml_models folder
4) Run main.py Python file.


Alternatively,
1) Download the entire project file from the link: https://drive.google.com/file/d/1o-iD1CTRWqyVce2qQmIAsaQwJf9vVWI7/view?usp=sharing
2) Extract the project folder into a path of your choice
3) Run the main.py file from the folder.

**Credits**: This project was jointly developed with Ronald Pai, Yuexin Pan, Yihan Li and Ziyi Wang. It was supervised by Dr. Basem Suleiman and Abdallah Lakhdari. 
