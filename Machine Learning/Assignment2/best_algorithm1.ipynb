{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import numpy as np\n",
    "from numpy import mean, absolute\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "#Importing libraries for pre-processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "#Importing libraries for Regressors\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import make_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ForestFires data set\n",
    "forestfire_data = pd.read_csv('./forestfires.csv')\n",
    "\n",
    "# Encode the data\n",
    "encodeData = LabelEncoder()\n",
    "\n",
    "#Convert months to integer using label encoder\n",
    "encodeData.fit(forestfire_data['month'])\n",
    "forestfire_data['encoded_months'] = encodeData.transform(forestfire_data['month'])\n",
    "\n",
    "#Convert days to integer using label encoder\n",
    "encodeData.fit(forestfire_data['day'])\n",
    "forestfire_data['encoded_days'] = encodeData.transform(forestfire_data['day'])\n",
    "\n",
    "#FEATURE SELECTION\n",
    "#select top 3 features based on highest co-relation\n",
    "featureSelected = ['temp', 'FFMC', 'DMC']\n",
    "dataX = forestfire_data[featureSelected]\n",
    "\n",
    "#Select area into Y\n",
    "dataY = forestfire_data['area']\n",
    "\n",
    "#split the dataset into training data (80%) and testing data (20%) using sklearn's train_test_split method\n",
    "trainingData, testingData, trainingArea, testingArea = train_test_split(dataX, dataY, test_size = 0.2)\n",
    "\n",
    "#Reshape the trainingArea\n",
    "trainingArea = trainingArea.values.reshape(trainingArea.size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for calculation root mean squared error\n",
    "def root_mean_squared_error(givenValues, predictedValues):\n",
    "    return np.sqrt(mean_squared_error(givenValues, predictedValues))\n",
    "\n",
    "#Define function for calculating mean absolute deviation\n",
    "def mean_absolute_deviation(predictedValues):\n",
    "    return np.mean(np.absolute(predictedValues - mean(predictedValues)))\n",
    "\n",
    "#Define function for calulating negative log likelihood\n",
    "def negative_log_likelihood(givenValues, predictedValues):\n",
    "    givenValues_length = givenValues.shape[0]\n",
    "    \n",
    "    m = - (givenValues_length / 2) * np.log(2 * np.pi * (np.var(predictedValues)))\n",
    "    n = 0\n",
    "    \n",
    "    for iterations in range(givenValues_length):\n",
    "        n = n + (givenValues[iterations] - predictedValues[iterations]) ** 2\n",
    "    n = n - n / (2 * (np.var(predictedValues)))\n",
    "    \n",
    "    return (m + n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing SUPPORT VECTOR REGRESSION\n",
    "\n",
    "#Initialize scaler\n",
    "scaler_SVR = StandardScaler()\n",
    "\n",
    "#Define parameter grid for support vector regressor\n",
    "parameterGrid_SVR = {'C': [0.01, 0.1, 1, 10], 'epsilon': [10, 1, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']}\n",
    "\n",
    "#Define scorer\n",
    "scorerRMSE = make_scorer(root_mean_squared_error, greater_is_better = False)\n",
    "\n",
    "#Implement grid search cross validation using 10 folds\n",
    "SVR_grid = GridSearchCV(SVR(), parameterGrid_SVR, refit = True, verbose = 0, scoring = scorerRMSE, cv = 10)\n",
    "SVR_grid.fit(scaler_SVR.fit_transform(trainingData), scaler_SVR.fit_transform(trainingArea))\n",
    "\n",
    "#Predict the values for areas\n",
    "predictedValues = SVR_grid.predict(testingData)\n",
    "\n",
    "#Calculate Root Mean Squared Error\n",
    "SVR_RMSE = root_mean_squared_error(testingArea, predictedValues)\n",
    "\n",
    "#Calculate Mean Absolute Deviation\n",
    "SVR_MAD = mean_absolute_deviation(predictedValues)\n",
    "\n",
    "#Calcute negative log likelihood\n",
    "SVR_NLL= negative_log_likelihood(testingArea.values, predictedValues)\n",
    "\n",
    "print('Root Mean Squared Error for Support Vector Regression: ', SVR_RMSE)\n",
    "print('Mean Absolute Deviation for Support Vector Regression: ', SVR_MAD)\n",
    "print('Negative Log Likelihood for Support Vector Regression: ', SVR_NLL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
