{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9e7Kj0wNWCgt",
    "outputId": "f7799c34-3102-4bd2-d515-a6691abfe939"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Dataset contains of 30,000 training examples, images of \n",
    "size 28 * 28. Thus, converting image pixels into matrix of \n",
    "dimension: 30,000 * 784.\n",
    "\n",
    "Split data set in 80:20 ratio for trainging and validation \n",
    "respectively.\n",
    "\n",
    "'''\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import datetime\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# load the training images files\n",
    "with h5py.File('../Input/images_training.h5', 'r') as H:\n",
    "    trainingData = np.copy(H['datatrain'])\n",
    "\n",
    "# load the training labels\n",
    "with h5py.File('../Input/labels_training.h5', 'r') as H:\n",
    "    trainingLabel = np.copy(H['labeltrain'])\n",
    "\n",
    "# load the testing images\n",
    "with h5py.File('../Input/images_testing.h5', 'r') as H:\n",
    "    data_test = np.copy(H['datatest'])\n",
    "    testingData = data_test[:5000]\n",
    "\n",
    "# load the testing labels\n",
    "with h5py.File('../Input/labels_testing.h5', 'r') as H:\n",
    "    label_test = np.copy(H['labeltest'])\n",
    "    testingLabel = label_test[:5000]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''KNN CLASSIFIER'''\n",
    "\n",
    "'''\n",
    "Categorize the data into different classes.\n",
    "Calculated the similarity measure using Euclidean \n",
    "distance, which is defined as the absolute difference\n",
    "between the coordinates of two data points\n",
    "\n",
    "'''\n",
    "class KNN_Classifier():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    # Get training data and labels\n",
    "    def getData(self, trainingData, trainingLabel):\n",
    "        self.dataTrain = trainingData\n",
    "        self.labelTrain = trainingLabel\n",
    "        \n",
    "    # Function to predict classes\n",
    "    def predictionFunction(self, trainingData, totNeighbours = 5):\n",
    "        totalDistance = self.calculateDistance(trainingData)\n",
    "        \n",
    "        totalData = totalDistance.shape[0]\n",
    "        predictedLabel = np.zeros(totalData)\n",
    "        \n",
    "        # Compare distance with neighbours\n",
    "        for i in range(totalData):\n",
    "            closestNeighbours = []\n",
    "            labels = self.labelTrain[np.argsort(totalDistance[i, :])].flatten()\n",
    "            closestNeighbours = labels[:totNeighbours]\n",
    "            \n",
    "            predictedLabel[i] = Counter(closestNeighbours).most_common(1)[0][0]\n",
    "        return(predictedLabel)\n",
    "    \n",
    "    # Calculate euclidean distance\n",
    "    def calculateDistance(self, trainingData):\n",
    "        totalData = trainingData.shape[0]\n",
    "        totalSelfData = self.dataTrain.shape[0]\n",
    "        \n",
    "        dotProduct = np.dot(trainingData, self.dataTrain.T)\n",
    "        sumSquareTrain = np.square(trainingData).sum(axis = 1)\n",
    "        sumSquareSelfTrain = np.square(self.dataTrain).sum(axis = 1)\n",
    "        \n",
    "        totalDistance = np.sqrt(-2 * dotProduct + sumSquareSelfTrain + np.matrix(sumSquareTrain).T)\n",
    "        \n",
    "        return(totalDistance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''LOGISTIC REGRESSION'''\n",
    "\n",
    "'''\n",
    "Categorize the data into different classes.\n",
    "\n",
    "'''\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "# Computes probability of test samples belonging to a particular class\n",
    "def softmaxFunction(a):\n",
    "    return(np.exp(a) / np.exp(a).sum(axis = 1, keepdims = True))\n",
    "\n",
    "# Accelerate convergence to optimize performance  \n",
    "def softmaxGradientFunction(trainingData, trainingLabel, randomData):\n",
    "    SM = softmaxFunction(trainingData.dot(randomData))\n",
    "    var_a = range(trainingData.shape[0])\n",
    "    SM[var_a, trainingLabel] -= 1\n",
    "    return(trainingData.T.dot(SM) / trainingData.shape[0])\n",
    "\n",
    "# Check the performance of model by calculating error\n",
    "def softmaxLossFunction(trainingData, trainingDabel, randomData):\n",
    "    SM = softmaxFunction(trainingData.dot(randomData))\n",
    "    var_a = range(trainingData.shape[0])\n",
    "    return(-np.mean(np.log(SM[var_a, trainingLabel])))\n",
    "\n",
    "'''\n",
    "Tune the parameters such as learning rate, epoch, batch size etc.\n",
    "to properly fit the learning curve.\n",
    "\n",
    "'''\n",
    "def softmaxFitFunction(trainingData, trainingLabel, randomData, learningRate = 0.01, no_of_epochs = 100, tolerance = 1e-5, batchsize = 10):\n",
    "    old_random_data = randomData.copy()\n",
    "    index = 0\n",
    "    lossHistory = [softmaxLossFunction(trainingData, trainingLabel, randomData)]\n",
    "    totalRecords = trainingData.shape[0]\n",
    "    totalBatches = int(np.ceil(float(totalRecords) / batchsize))\n",
    "    \n",
    "    while index < no_of_epochs:\n",
    "        index = index + 1\n",
    "        randData = np.random.permutation(totalRecords)\n",
    "        \n",
    "        for i in range(totalBatches):\n",
    "            id_batch = randData[batchsize * i:min(batchsize * (i + 1), totalRecords)]\n",
    "            dataBatch, labelBatch = trainingData[id_batch], trainingLabel[id_batch]\n",
    "            randomData -= learningRate * softmaxGradientFunction(dataBatch, labelBatch, randomData)\n",
    "        \n",
    "        lossHistory.append(softmaxLossFunction(trainingData, trainingLabel, randomData))\n",
    "        \n",
    "        if(np.linalg.norm((randomData - old_random_data) / randomData.size) < tolerance):\n",
    "            break\n",
    "        \n",
    "        old_random_data = randomData.copy()\n",
    "        \n",
    "    return(randomData, lossHistory)\n",
    "\n",
    "# Predict classes\n",
    "def predictionFunction(randomData, trainingData):\n",
    "    return(np.argmax(softmaxFunction(trainingData.dot(randomData)), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy of the model\n",
    "# Accuracy = (Number of correct classifications / Total number of test examples used) * 100\n",
    "\n",
    "def calculateAccuracy(testingLabel, predictedLabel):\n",
    "        totalCount = predictedLabel == testingLabel\n",
    "        return((totalCount.sum() / len(totalCount)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose your classifier\n",
    "\n",
    "selectClassifier = input('1) K-NEAREST NEIGHBOURS \\n2) LOGISTIC REGRESSION\\n\\nPlease enter your choice and press enter: \\n' + '\\n')\n",
    "\n",
    "if(selectClassifier == '1'):\n",
    "    print('KNN CLASSIFIER:')\n",
    "    \n",
    "    batchSize = 2000\n",
    "    classifierModel = KNN_Classifier()\n",
    "    classifierModel.getData(trainingData, trainingLabel)\n",
    "\n",
    "    predictedLabel = []\n",
    "\n",
    "    # Calculate start time\n",
    "    startTime = datetime.datetime.now()\n",
    "    \n",
    "    # train the data\n",
    "    for i in range(int(len(testingData) / (2 * batchSize))):\n",
    "        tempList  = classifierModel.predictionFunction(testingData[i * batchSize:(i + 1) * batchSize])\n",
    "        predictedLabel = predictedLabel + list(tempList)\n",
    "\n",
    "    # Predict labels\n",
    "    for i in range(int(len(testingData) / (2 * batchSize)), int(len(testingData) / batchSize)):\n",
    "        tempList  = classifierModel.predictionFunction(testingData[i * batchSize:(i + 1) * batchSize])\n",
    "        predictedLabel = predictedLabel + list(tempList)\n",
    "\n",
    "    # Calculate end time\n",
    "    endTime = datetime.datetime.now()\n",
    "    \n",
    "    resultantAccuracy = calculateAccuracy(testingLabel, predictedLabel)\n",
    "    print('The accuracy of the model with KNN is: %.2f' % resultantAccuracy, '%')\n",
    "\n",
    "    # Creating output file contatining predicted labels\n",
    "    with h5py.File('../Output/predicted_labels.h5','w') as H:\n",
    "        H.create_dataset('output', data = predictedLabel)\n",
    "\n",
    "    print('Output file containing predicted labels is created by name \"predicted_labels.h5\" for KNN Classifier')\n",
    "    print(\"Total time taken by KNN classifier is\", (endTime - startTime).seconds, 'seconds.')\n",
    "    \n",
    "elif(selectClassifier == '2'):\n",
    "    print('LOGISTIC REGRESSION:')\n",
    "    '''\n",
    "    # Train the model\n",
    "    # Compute time taken to execute: (endTime - startTime)\n",
    "    '''\n",
    "    \n",
    "    randomData = np.random.randn(trainingData.shape[1], 10)\n",
    "\n",
    "    # Calculate start time\n",
    "    startTime = datetime.datetime.now()\n",
    "\n",
    "    #train the data\n",
    "    resultantData, lossHistory = softmaxFitFunction(trainingData, trainingLabel, randomData)\n",
    "\n",
    "    # Calculate end time\n",
    "    endTime = datetime.datetime.now()\n",
    "    \n",
    "    predictedLabel = predictionFunction(resultantData, testingData)\n",
    "    resultantAccuracy = calculateAccuracy(predictedLabel, testingLabel)\n",
    "\n",
    "    print('The accuracy of the model with Logistic Regression is: %.2f' % resultantAccuracy, '%')\n",
    "\n",
    "    print(\"Total time taken by Logistic Regression classifier model is\", (endTime - startTime).seconds, 'seconds.')\n",
    "    \n",
    "else: print('Invalid Choice')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LR_SID1490495249_SID2490278701_SID3490323780.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
